{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Currently missing what you would want to use as a set of controls.\n",
    "\n",
    "To what extent does the presence of a professional sports stadium act as a localized economic catalyst compared to broader metropolitan trends? Specifically, does the percentage growth in median property values (wealth), total business licenses (commercial activity), and employment rates (opportunity) of neighbourhoods within a 2 mile radius of a stadium significantly outpace the growth of the surrounding neighbourhoods within the same city? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professional sports stadiums are often significantly large venues that host often profitable sporting events for the NFL, NBA, NHL, and other sporting leagues. Stadiums are also culturally significant as events like the Super Bowl, hosted in the Caesars Superdome, New Orleans, Louisiana in 2025, had around 120 million viewers and around 76,000 filled seats.It can be assumed that stadiums  stimulate economic activity around the local area as businesses take advantage of the large foot traffic stadiums create, creating more jobs, increasing spending, tourism, and property value <sup>[2](#https://www.researchgate.net/publication/46552225_How_Does_a_New_Sports_Stadium_Affect_Housing_Values_The_Case_of_Fedex_Field)</sup>. \n",
    "\n",
    "\n",
    "However, studies and articles conclude that the construction of new stadiums yields negligible improvements to local employment<sup>[3](#https://doi.org/10.1002/pam.22534)</sup>, and may take spending away from local businesses as people spend it on stadium related costs instead. Additionally, stadium construction is often funded by public subsidies that can be used on other local construction projects or programs. While stadiums may generate a localized economic surge within their immediate vicinity<sup>[1](#https://www.aimspress.com/article/doi/10.3934/NAR.2024024?viewType=HTML)</sup> and foster civic identity and pride, analysts argue their regional economic impact is limited.\n",
    "\n",
    "\n",
    "For this project, we are observing how professional sports stadiums affect the local economy. In a 2024 research paper, Antolini Valerio analyzes trends in GDP per capita in Turin, Italy around the construction of a new and technologically impressive NFL stadium called a next-generation stadium. The writer found a causal relationship between an increase in GDP per capita with the new stadium compared to other regions of Italy that showed comparatively lower growths in GDP per capita1. The paper provides some insights on how new and expensive stadiums can change local economic production. In a study by Charles Tu, the construction of a stadium causes homes to be sold at a lower price, but over longer periods of time land value increases. The study shows that there are changes to local property values which will be examined and compared in our own data. The paper by Bradbury and co, details the large public costs of newly constructed professional sports stadiums compared to how little economic improvement they provide. This review on the stadiums and their impacts show the confounding ethical, public, and economic variables that we need to interpret to understand how professional sports stadiums impact localized economies.\n",
    "\n",
    "Citations:\n",
    "\n",
    "1. Antolini, V. The Economic Impact of Next-Generation Stadiums: Evidence from the Juventus Stadium Using  Synthetic Control Methodology. Natl. Account. Rev. 2024, 6, 531–547. https://www.aimspress.com/article/doi/10.3934/NAR.2024024?viewType=HTML \n",
    "\n",
    "2. Tu, Charles. (2005). How Does a New Sports Stadium Affect Housing Values? The Case of Fedex Field. Land Economics. https://www.researchgate.net/publication/46552225_How_Does_a_New_Sports_Stadium_Affect_Housing_Values_The_Case_of_Fedex_Field\n",
    "\n",
    "3. Bradbury, J. C., Coates, D., & Humphreys, B. R. (2024). Public policy toward professional sports stadiums: A review. Journal of Policy Analysis and Management, 43, 899–937. https://doi.org/10.1002/pam.22534 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n",
    "We predict that the presence of a professional sports stadium  will cause overall economic growth, specifically through an increase in total businesses and employment rates for the neighborhoods within a 2-mile radius of a stadium when compared to other neighborhoods within the same city, however this growth will be inversely correlated with property values in the same area. We predict that median housing prices within the 2 mile radius will grow at a lower rate than the city-wide average due to negative externalities from the stadium like pollution due to smog, construction, energy consumption, traffic congestion, and noise, all of which can have a stronger negative effect on property values more than the positive externalities from the stadium such as the business growth and infrastructure improvements. Neighborhoods a few miles away will see higher housing prices as people would want to live within range of the stadium to enjoy events, but also out of range to avoid the negative effects. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- Dataset #3\n",
    "  - Dataset Name: ACS 2024 5-Year Estimates Selected Housing Characteristics (DP04)\n",
    "  - Link to the dataset: https://data.census.gov/table/ACSDP5Y2024.DP04?q=DP04&g=010XX00US$8600000 \n",
    "  - Number of observations: 30,238 (after cleaning), 33,773 (before cleaning)\n",
    "  - Number of variables: 13 \n",
    "  - Description of the variables most relevant to this project: \n",
    "    - median_home_value: Midpoint value of owner-occupied housing units; used to assess neighborhood wealth/cost of entry\n",
    "    - median_gross_rent: Monthly rent plus estimated utility costs; used to assess local affordability.\n",
    "    - total_housing_units: The total count of homes in a ZCTA; used to normalize other metrics.\n",
    "    - built_2020_or_later: Count of newly constructed units; serves as a proxy for recent neighborhood growth and investment.\n",
    "    - zip_code: Extracted from the geographic name to allow for merging with stadium location data.\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project: \n",
    "    - Margin of Error (MOE): Because the ACS is a survey, smaller geographies may have high MOEs, making specific neighborhood estimates less precise.\n",
    "    - Self-Reporting Bias: Home values are based on the respondent's perception of value rather than actual market sale prices or tax assessments.\n",
    "    - Recency: While 2024 is the most recent 5-year estimate, it is a rolling average, meaning it might not fully capture immediate real estate spikes caused by very recently opened stadiums.\n",
    "\n",
    "We plan to combine this Census housing characteristics data with a dataset of stadium locations (which includes latitude/longitude). To merge the datasets, we will perform a spatial join by converting the stadium latitude and longitude coordinates into ZIP Code Tabulation Areas (ZCTAs) using the geopandas library. Using the zip_code column I created in this notebook, we will perform an inner join to compare housing metrics in ZIP codes that contain a professional sports stadium against those that do not, as well as analyzing how distance from a stadium affects home values and rent burden.\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Census Bureau: Selected Housing Characteristics (DP04)\n",
    "\n",
    "This dataset is from the U.S. Census Bureau’s American Community Survey (ACS) 2024 5-Year Estimates. It provides a comprehensive profile of the housing stock, financial costs of homeownership and renting, and physical characteristics of housing units across specific geographies. The ACS is an ongoing survey that provides characteristics data, helping planners, researchers, and real estate analysts understand the quality of life and economic burden of housing in specific regions.\n",
    "\n",
    "The dataset includes several critical metrics for housing market analysis. Median Home Value and Median Gross Rent are provided in US Dollars, they represent the midpoint of all reported values, where half are higher and half are lower. A healthy housing market typically sees these values rising in line with local inflation, whereas stagnant or falling values may indicate economic decline. Housing Tenure (Owner vs. Renter occupied) is measured in raw counts and percentages, a high owner-occupancy rate suggests neighborhood stability, while high renter-occupancy can indicate a transient population or an area with high density multi-family development. Another important metric is Gross Rent as a Percentage of Household Income (GRAPI). The Census Bureau generally considers households spending 30% or more of their income on housing to be \"rent burdened,\" while those spending 50% or more are \"severely rent burdened,\" indicating a potential crisis in affordability.\n",
    "\n",
    "A major concern with this dataset is its reliance on self-reporting and sampling error. Because this is a survey of a sample of the population rather than a full count, every estimate comes with a Margin of Error (MOE). In smaller geographic areas (like specific census tracts near a stadium), the MOE can be quite large relative to the estimate, making the data less reliable. There is also a risk of Non-response Bias, when certain demographics, such as very high-income individuals or undocumented residents, may be less likely to respond to the survey accurately. Finally, \"Median Value\" is based on the respondent’s perception of what their home is worth, which may differ from actual market sale prices or tax appraisals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 3535 rows with missing home values.\n",
      "Cleaned data saved to data/02-processed/census_housing_char_clean.csv\n",
      "Final Data Shape: (30238, 13)\n",
      "           geo_id neighborhood_name  total_housing_units  occupied_units  \\\n",
      "1  860Z200US00601       ZCTA5 00601               7570.0          5768.0   \n",
      "2  860Z200US00602       ZCTA5 00602              17610.0         12954.0   \n",
      "3  860Z200US00603       ZCTA5 00603              26239.0         20131.0   \n",
      "4  860Z200US00606       ZCTA5 00606               2681.0          1860.0   \n",
      "5  860Z200US00610       ZCTA5 00610              12636.0          9604.0   \n",
      "\n",
      "   vacant_units  built_2020_or_later  built_2010_to_2019  built_2000_to_2009  \\\n",
      "1        1802.0                  0.0               209.0               782.0   \n",
      "2        4656.0                  8.0               743.0              1693.0   \n",
      "3        6108.0                 26.0              1161.0              4405.0   \n",
      "4         821.0                  5.0                26.0               222.0   \n",
      "5        3032.0                 30.0               388.0              1451.0   \n",
      "\n",
      "   median_home_value  median_gross_rent  single_family_detached  \\\n",
      "1            94200.0              427.0                  5834.0   \n",
      "2           121400.0              475.0                 12364.0   \n",
      "3           152900.0              475.0                 17115.0   \n",
      "4           114000.0              413.0                  2250.0   \n",
      "5           117900.0              579.0                  9203.0   \n",
      "\n",
      "   large_apartments_20plus_units zip_code  \n",
      "1                          105.0    00601  \n",
      "2                          179.0    00602  \n",
      "3                          905.0    00603  \n",
      "4                            0.0    00606  \n",
      "5                          195.0    00610  \n",
      "  zip_code  median_home_value\n",
      "1    00601            94200.0\n",
      "2    00602           121400.0\n",
      "3    00603           152900.0\n",
      "4    00606           114000.0\n",
      "5    00610           117900.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "raw_data_path = 'data/00-raw/ACSDP5Y2024.DP04-Data.csv'\n",
    "metadata_path = 'data/00-raw/ACSDP5Y2024.DP04-Column-Metadata.csv'\n",
    "\n",
    "os.makedirs('data/02-processed', exist_ok=True)\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_csv(raw_data_path, low_memory=False)\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"Files not found. Please ensure they are in 'data/00-raw/'\")\n",
    "    df_raw = pd.DataFrame() \n",
    "\n",
    "cols_to_keep = {\n",
    "    # Identifiers\n",
    "    'GEO_ID': 'geo_id',\n",
    "    'NAME': 'neighborhood_name',\n",
    "    \n",
    "    # Inventory\n",
    "    'DP04_0001E': 'total_housing_units',\n",
    "    'DP04_0002E': 'occupied_units',\n",
    "    'DP04_0003E': 'vacant_units',\n",
    "    \n",
    "    # Building Age (New Construction Proxy)\n",
    "    'DP04_0017E': 'built_2020_or_later',\n",
    "    'DP04_0018E': 'built_2010_to_2019',\n",
    "    'DP04_0019E': 'built_2000_to_2009',\n",
    "    \n",
    "    # Financials\n",
    "    'DP04_0089E': 'median_home_value',\n",
    "    'DP04_0134E': 'median_gross_rent',\n",
    "    \n",
    "    # Structure Type (Density Proxy)\n",
    "    'DP04_0007E': 'single_family_detached',\n",
    "    'DP04_0013E': 'large_apartments_20plus_units'\n",
    "}\n",
    "\n",
    "\n",
    "if 'DP04_0001E' in df_raw.columns:\n",
    "    available_cols = [c for c in cols_to_keep.keys() if c in df_raw.columns]\n",
    "    df_clean = df_raw[available_cols].rename(columns=cols_to_keep)\n",
    "    \n",
    "elif 'Label (Grouping)' in df_raw.columns:\n",
    "    print(\"Detected Profile Format. Transposing...\")\n",
    "    df_clean = df_raw.set_index('Label (Grouping)').T\n",
    "    df_clean.index.name = 'neighborhood_name'\n",
    "    df_clean = df_clean.reset_index()\n",
    "    \n",
    "    pass \n",
    "else:\n",
    "    df_clean = df_raw.copy()\n",
    "\n",
    "def clean_census_number(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    s = str(val).strip()\n",
    "    if s in ['(X)', '-', 'N', '**', '***', '(V)']: return np.nan\n",
    "    s = s.replace(',', '').replace('+', '').replace('$', '').replace('±', '')\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "cols_to_convert = [c for c in df_clean.columns if c not in ['geo_id', 'neighborhood_name']]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df_clean[col] = df_clean[col].apply(clean_census_number)\n",
    "\n",
    "df_clean = df_clean.dropna(how='all')\n",
    "\n",
    "if 'median_home_value' in df_clean.columns:\n",
    "    print(f\"Dropping {df_clean['median_home_value'].isna().sum()} rows with missing home values.\")\n",
    "    df_clean = df_clean.dropna(subset=['median_home_value'])\n",
    "\n",
    "df_clean['zip_code'] = df_clean['neighborhood_name'].str.extract(r'(\\d{5})')\n",
    "\n",
    "output_path = 'data/02-processed/census_housing_char_clean.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")\n",
    "print(f\"Final Data Shape: {df_clean.shape}\")\n",
    "print(df_clean.head())\n",
    "print(df_clean[['zip_code', 'median_home_value']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing Market Summary Statistics:\n",
      "       median_home_value  median_gross_rent  total_housing_units  \\\n",
      "count           30238.00           25256.00             30238.00   \n",
      "mean           297885.33            1181.74              4790.44   \n",
      "std            252897.43             532.58              6378.66   \n",
      "min             11700.00             225.00                 7.00   \n",
      "25%            148700.00             815.00               500.00   \n",
      "50%            222000.00            1021.00              1693.50   \n",
      "75%            360300.00            1417.00              6993.75   \n",
      "max           2000000.00            3500.00             47746.00   \n",
      "\n",
      "       vacant_units  built_2020_or_later  \n",
      "count      30238.00             30238.00  \n",
      "mean         488.23                95.08  \n",
      "std          810.93               260.40  \n",
      "min            0.00                 0.00  \n",
      "25%           63.00                 0.00  \n",
      "50%          209.00                13.00  \n",
      "75%          604.00                73.00  \n",
      "max        26870.00              5790.00  \n",
      "\\Overall Vacancy Rate in Dataset: 10.19%\n",
      "Number of neighborhoods with new construction since 2020: 20,164\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY STATISTICS\n",
    "\n",
    "important_cols = [\n",
    "    'median_home_value', \n",
    "    'median_gross_rent', \n",
    "    'total_housing_units', \n",
    "    'vacant_units', \n",
    "    'built_2020_or_later'\n",
    "]\n",
    "\n",
    "print(\"Housing Market Summary Statistics:\")\n",
    "summary = df_clean[important_cols].describe().round(2)\n",
    "print(summary)\n",
    "\n",
    "avg_vacancy = (df_clean['vacant_units'].sum() / df_clean['total_housing_units'].sum()) * 100\n",
    "print(f\"\\Overall Vacancy Rate in Dataset: {avg_vacancy:.2f}%\")\n",
    "\n",
    "new_construction_areas = df_clean[df_clean['built_2020_or_later'] > 0].shape[0]\n",
    "print(f\"Number of neighborhoods with new construction since 2020: {new_construction_areas:,}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> All of our data is from the US Census and a Kaggle Dataset of Stadium locations. This means it is all collected through the informed consent of the individuals and public geographic data.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    ">Census Data can be biased, and certain individuals can sometimes fail to report sometimes. To mitigate this, we are taking our data over a course of 10+ years to judge median incomes and percentage increase, rather than raw income increases. This ensures that the bias will be mitigated due to differences in economic parity between cities and neighborhoods\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    ">This project minimizes exposure to personally identifiable information (PII) by exclusively using public, aggregated datasets that do not contain individual level records. \n",
    "\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    ">Downstream bias is addressed by using aggregated Census demographic variables (e.g., race composition, housing tenure, income distribution) to examine whether observed neighborhood-level outcomes differ across demographic contexts.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    ">Since all datasets are public and non-PII, risk is minimal; nonetheless, standard safeguards such as access control and versioned backups are used.\n",
    "\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    ">Because the project uses only publicly available, aggregated data with no personal identifiers, individual data removal requests are not applicable.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    ">Data will be retained only for the duration of the project and any required academic review period, after which local copies will be deleted. Public sources can be re-downloaded if replication is needed.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    ">We acknowledge that quantitative data may not capture lived experiences such as cultural displacement or housing insecurity. To address this, findings are contextualized using urban economics literature and prior case studies of stadium-led development, and assumptions are explicitly stated.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    ">We explicitly examine known biases, including undercounting, survivorship bias due to displacement, and temporal smoothing in ACS data. We mitigate these through difference-in-differences analysis, sensitivity checks, and comparisons with control neighborhoods.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    ">Visualizations and summary statistics are designed to avoid misleading interpretations. We present confidence intervals, margins of error where applicable, and avoid framing aggregate improvements as universal benefits without qualification.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    ">No PII is used or displayed in analysis outputs. All results are reported at an aggregated geographic level.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    ">The analysis workflow is fully documented and reproducible. Code, data sources, assumptions, and preprocessing steps are clearly recorded to enable auditing or revision if issues are discovered.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    ">The project does not involve predictive models that make decisions about individuals. Demographic variables are used analytically to detect inequitable outcomes, not to allocate resources or make judgments about individuals or groups.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    ">We explicitly compare outcomes across demographic subgroups (e.g., renter-heavy vs owner-heavy tracts) to assess whether stadium proximity is associated with uneven economic effects.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    ">We avoid relying on a single metric (e.g., median income) and instead evaluate multiple indicators such as rent burden, housing values, employment, and business activity to reduce metric-induced bias.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - \n",
    ">All analytical methods (e.g., difference-in-differences) are explained in plain language, and results are interpretable without requiring advanced statistical background.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    ">We clearly communicate limitations, including data bias, inability to observe displaced residents directly, and the non-causal nature of some findings. Conclusions are framed cautiously to avoid overgeneralization.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    ">This project is an academic analysis and does not involve a deployed system or model requiring ongoing monitoring.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    ">As no automated decisions or services are deployed, formal redress mechanisms are not applicable. However, findings are presented responsibly to avoid harm through misinterpretation.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    ">No production system or model is deployed.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    ">We acknowledge the risk that findings could be misused to justify harmful development practices. To mitigate this, results are contextualized ethically, emphasizing distributional impacts rather than framing stadium development as inherently beneficial or harmful.\n",
    "\n",
    "\n",
    "Additionally:\n",
    "\n",
    "Longtime residents of these areas can be priced out of their homes and neighborhoods, especially as the price of housing increases, leading to gentrification around the stadium.\n",
    "\n",
    "Stadiums can bring seasonal work, but not permanent employment, causing the surrounding area to see greater short term economic growth but realistically this employment structure is unstable. \n",
    "\n",
    "Stadiums can affect the local environment, causing more pollution due to construction, traffic, energy consumption, etc. This pollution leads to the decreased quality of life around a stadium, causing people to move further away to still enjoy benefits without the drawbacks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Communication over Discord. Respond within 4-5 hours. Virtual meetings weekly and more as needed, Tuesday at 4. Add more meetings as needed*\n",
    "* *Speak up and be respectful with your ideas. If you want to change something, justify why to everyone.*\n",
    "* *Decisions will be made via group discussion in meetings. If you aren’t present when a decision is being made, then you will need to deal with it.*\n",
    "* *You will be expected to keep track of your own tasks and monitor progress. We will use a Kanban Board to track progress for each task.*\n",
    "* *If you are struggling with a task, feel free to reach out in the Discord and ask for help whether it is clarification, asking to divide the work with someone because you are busy, or switching your task with someone else because you both agree you’d do better with the other’s task.*\n",
    "* *Make sure you add clear comments to your code to explain what you’re doing for other people, as well as for grading.*\n",
    "* *If you see something in someone else’s section that could be improved, message them with your suggestion rather than adding it blindly.*\n",
    "* *Do your fair share of work. We are all adults, and we know whether we are doing enough work to be considered good teammates. This is a social contract that we all need to uphold if we want to succeed.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them\n",
    "\n",
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting |\n",
    "|-------------|--------------|--------------------------|--------------------|\n",
    "| 2/10/25 | 4:00 PM | Preliminary EDA (all) | Discuss findings and difficulties; decide on a definite direction for wrangling data |\n",
    "| 2/17/25 | 4:00 PM | EDA of assigned datasets | Discuss findings; determine who should collaborate on which datasets |\n",
    "| 2/24/25 | 4:00 PM | EDA and beginning individual analysis | Conclude analysis, divide report sections, discuss project check-in |\n",
    "| 3/3/25 | 4:00 PM | Final draft of respective report sections | Final tweaks and changes to report |\n",
    "| 3/10/25 | 4:00 PM | Written report and script for final video | Logistics for video filming; address any issues with report or script |\n",
    "| 3/17/25 | 4:00 PM | Video submission | Review video, make final changes to report, and submit all outstanding assignments |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
